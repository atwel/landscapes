{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file recreates table 1 of Herrmann et al.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import packages and files\n",
    "from itertools import compress, product\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import array\n",
    "import random\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import operator\n",
    "import importlib\n",
    "#import functions defining the layered landscape\n",
    "from LayeredLandscapeFunctions import *\n",
    "from Landscapes import *\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This functions takes as an input the string of file name params,e.g. \"N-10_K1=3_K2=9_I=20\"\n",
    "#then loads in the mapping and generates the table one statistics we want:num_local_optima,num_clusters,fo_bar\n",
    "def Get_Table_1_Stats(our_files,param_combo):\n",
    "    loc_opt = []\n",
    "    num_clusters= []\n",
    "    fo_bars = []\n",
    "    for file_name in our_files:\n",
    "        \n",
    "        if param_combo in file_name:\n",
    "            try:\n",
    "                df_transition = pd.read_csv(str(file_name.replace(\"_mapping\",\"\")))\n",
    "                df_map = pd.read_csv(str(file_name))\n",
    "\n",
    "                df_transition = df_transition.set_index('Unnamed: 0')#reset index\n",
    "\n",
    "                Mat = Markov_Clustering(df_transition) #get markov cluster matrix\n",
    "                MarkClusMatrix = nx.from_numpy_matrix(Mat) #convert to adjacency matrix undirected\n",
    "                ##get the mapping and restrict it to maximas\n",
    "                df_map_restricted = df_map[df_map.Maxima==1]\n",
    "\n",
    "                #get the connected components/clusters\n",
    "                G= nx.Graph(MarkClusMatrix)\n",
    "                Components = list(nx.connected_components(G)) #list the components\n",
    "                df_map_restricted['cluster']=0 #create variable and set to zero\n",
    "                ##loop throught the components and assign clusters\n",
    "                j=0 #number to index number of components\n",
    "                NumComp = len(Components)\n",
    "                for comp in Components:\n",
    "                    for i in comp:\n",
    "                        df_map_restricted['cluster'].iloc[i]=j\n",
    "                    j+=1\n",
    "\n",
    "\n",
    "                #identify cluster with the global maxima\n",
    "                Cluster_of_Maxima = df_map_restricted.loc[df_map_restricted.Fitness.idxmax()].cluster\n",
    "                ##set the table variables\n",
    "                num_local_optima = len(df_map_restricted)\n",
    "                num_clust = NumComp\n",
    "                fo_bar = len(df_map_restricted[df_map_restricted.cluster ==Cluster_of_Maxima ]) / num_local_optima\n",
    "                loc_opt.append(num_local_optima)\n",
    "                num_clusters.append(num_clust)\n",
    "                fo_bars.append(fo_bar)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "    return [np.average(loc_opt),np.std(loc_opt),np.average(num_clusters),np.std(num_clusters),np.average(fo_bars),np.std(fo_bars)] \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "our_files = glob.glob(\"./Results_LON_Simulations/*mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = []\n",
    "for file in our_files:\n",
    "    \n",
    "    if re.findall(\"K1\",file):\n",
    "        all_files.extend(re.findall(\"K1=\\d_K2=\\d\",file))\n",
    "    else:\n",
    "        all_files.extend(re.findall(\"K=\\d\",file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "List_file_params = set(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get a list of file names\n",
    "\n",
    "##loop over them\n",
    "Table_Stats = df_ = pd.DataFrame(index=List_file_params, columns=['AVG num_local_optima',\"SD num_optima\",'AVG num_clusters', \"SD clusters\",'AVG fo_bar',\"SD fo_bar\"])\n",
    "\n",
    "for params in List_file_params:\n",
    "    \n",
    "    Table_Stats.loc[params] = Get_Table_1_Stats(our_files,params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table_Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Iterated_Local_Search(Landscape1, Landscape2, Landscape_Weights, M, D,t, NumSims)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
